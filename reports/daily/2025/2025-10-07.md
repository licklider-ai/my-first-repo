 LogicBench テストレポート（2025-10-07）

## 🧩 作業概要
本日は、LogicBench の評価実行環境（`lb_runtime.py` / `eval_runner.py`）を改良し、  
OpenAI API のレートリミット対応および出力の正規化・採点分析を行った。

主な実施項目は以下の通り：

- ✅ `lb_runtime.py` を新規実装（`orjson`対応・ログ基盤整備）
- ✅ API リトライ・指数バックオフ処理を追加（429対応）
- ✅ `eval_runner.py` にスリープ制御・逐次追記処理を導入（中断時の安全性向上）
- ✅ OpenAI API（`gpt-4o-mini`）を用いた20問ベンチマークを開始
- ⚠️ 実行途中で「RateLimitError（429 / RPD=200件）」が発生し、処理停止
- ✅ 既存ログ (`logs/calls/*.json`) から結果を復元し、採点・分析を実施

---

## ⚙️ 実行環境
| 項目 | 内容 |
|------|------|
| 実行環境 | Ubuntu (WSL2) |
| 仮想環境 | `.venv` (Python 3.12) |
| モデル | `gpt-4o-mini` |
| 評価スクリプト | `scripts/eval_runner.py` |
| ログ保存先 | `logs/calls/` / `logs/errors/` |
| 出力ファイル | `runs/pred_v4.jsonl`（途中）／`runs/pred_from_logs.jsonl`（復元版） |
| スリープ制御 | `LB_SLEEP_S=21` 秒／リトライ最大3回 |

---

## 📊 テスト実行状況
実際のAPI呼び出しは 8件で上限に到達。  
429エラー（RPD上限200件／日）により残り12件は停止。

その後、`logs/calls` からレスポンスを復元して採点。

| ステップ | 状況 |
|-----------|------|
| `runs/pred_v4.jsonl` | 生成途中で停止（8件） |
| `runs/pred_from_logs.jsonl` | ログから再構築（8件） |
| 採点スクリプト | `pred_v4_scored_lenient.csv` / `pred_v4_summary_lenient.csv` 出力済み |

---

## 🧮 採点結果（暫定）
位置マッチ（dev/gold/pred 同インデックス対応）で採点した結果：

| id | gold | pred_norm | 判定 |
|----|------|------------|------|
| auto:873040127__16 | 7   | YES | × |
| auto:873040127__2  | YES | YES | ○ |
| auto:873040127__20 | A   | YES | × |

**正答数：1 / 3 → 33.3%**

すべての問題が `category=unknown` だったため、カテゴリ別分析は保留。

---

## 💰 API利用量（概算）
- 実行件数：8件
- 推定トークン数：入力400 + 出力250 = 650 tok/件  
- **概算コスト：\$0.00672 USD**（8件ベース）

（実測 `usage.jsonl` が未生成のため推定値）

---

## ⚠️ 発生した問題
| 種別 | 内容 | 対応 |
|------|------|------|
| **RateLimitError (429)** | 1分間および1日あたりのリクエスト上限に達した | → `LB_SLEEP_S=21` で緩和、RPDは翌日リセット待ち |
| **RPD上限 (200件/日)** | 無料／非課金組織制限 | → 課金設定追加で解放予定 |
| **出力のブレ** | モデル出力が `T`/`F`/`True`/`False` など曖昧 | → 正規化ルール追加（T/F→YES/NO）で改善済み |
| **カテゴリ欠損** | `dev_20.jsonl` に category フィールドなし | → 次回テスト前に手動追加を予定 |

---

## 🔍 改善・分析方針（次回対応）
1. **API側**
   - RPD制限解除（課金設定の有効化または翌日再実行）
   - RPM制御は現状 `LB_SLEEP_S=21` で十分

2. **採点ロジック**
   - gold の型（YES/NO・A〜D・数値）に応じて抽出ルールを切替（`lenient2`版導入済）

3. **出力制御**
   - `eval_runner.py` の system prompt を  
     `"You are a strict grader. Respond with one token (Answer: <token>)"` に差し替え予定

4. **カテゴリ別分析**
   - `data/dev_20.jsonl` に `"category"` フィールドを追加し、  
     分野別（数理・論理・推論など）の正答率を可視化予定

---

## 🗓️ 明日の予定（10月8日）
- 9:00（日本時間）以降に RPD 制限リセットを確認
- 20問ベンチマークを再開（gpt-4o-mini, sleep=21s）
- `pred_v5.jsonl` を生成 → `*_scored_lenient2.csv` で採点
- カテゴリ別・回答形式別（Yes/No, Choice, Numeric）分析

---
