# 🗓️ 日報（2025年10月6日）

## 🧩 作業内容
- `LogicBench` のローカルテストを継続実行  
  - コマンド:  
    ```bash
    python3 scripts/eval_runner.py data/dev_20.jsonl runs/pred_v3.jsonl
    ```
  - モデル: `gpt-4o-mini`
  - 結果: 正答率 0.00%（20問中0問正解）
- 結果をもとに、**精度改善方針を検討**
  - モデルを `gpt-4o` に変更して再評価する方針を決定  
  - 出力形式を厳格に制限するプロンプト（`bqa_mc_strict.txt`）を作成  
  - 採点の誤判定防止（出力末尾1文字抽出ロジック）の提案  
- 実行環境での挙動を確認  
  - `skip=20` により全問スキップされていたことを特定  
  - `model` 引数が `eval_runner.py` に反映されず、`gpt-4o-mini` 固定になっている問題を確認  
  - 再実行時の `null` 出力の原因を分析し、修正手順を整理  

---

## ⚙️ つまずいた点・トラブルシュート
| 発生内容 | 原因 | 対応・解決策 |
|-----------|------|---------------|
| `You: command not found` エラー | プロンプト文をそのままシェルで実行していた | ヒアドキュメント形式でファイル保存（`cat <<'EOF' ... EOF`）に変更 |
| `model=gpt-4o-mini` のまま固定 | `--model` 引数がスクリプト内で無視されていた | `grep -n "add_argument"` で引数名確認予定、または固定値を上書き |
| `skip=20` により全スキップ | 既存結果をキャッシュとしてスキップしていた | 出力ファイル名を変更（`runs/pred_v4_gpt4o_t0.jsonl`）または `--force` 使用 |
| 出力がすべて `null` | モデル未実行・旧結果参照 | 新プロンプト＋`--force` 再実行で修正予定 |

---

## 今後の予定
- `eval_runner.py` の `--model` 引数挙動を確認し、`gpt-4o` での再実行を実施  
- 厳格出力（A/B/C/Dのみ）＋正規化処理を組み込んで再採点  
- 正答率の改善を確認後、週報にまとめて共有予定  

---

